{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis on MovieLens 100K Dataset\n",
    "\n",
    "This notebook shows the process of making decisions on features by feature analysis. The purpose of feature analysis is to choose the influential feature and improve the model performance. The process could be arranged as:\n",
    "1. [Feature Preprocessing]: Fixed Dataset, NaN value filled in and feature engineering.\n",
    "\n",
    "2. [Feature Analysis]: Feature correlation on numerical features\n",
    "3. [Feature Analysis]: Chi-Square test of independence on categorical features\n",
    "4. [Feature Analysis]: Two-Sample z-Test on numerical features\n",
    "5. [Feature Analysis]: Feature importance on random forest model and permutation importance\n",
    "6. [Decision]: make priority on features\n",
    "\n",
    "The problem is formulated as: \n",
    "- With limited time and resources, which feature should be considered including in model first.\n",
    "\n",
    "- It could be treated as a CTR problem in recommender system by setting `label` as movie rating larger than 3 as 1, movie rating lower than 3 as 0, and drop the movie rating 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Preprocessing: Dataset\n",
    "`ML100K` generates the dataset and uses `random_seed` to make sure reproducibility. The feature `age_interval` and `freshness` are generated by feature engineering:\n",
    "\n",
    "- `age_interval`: bucketize `age` feature by 25% equally samples\n",
    "\n",
    "- `freshness`: use `timestamp` and `year` to generate `freshness` to represent the time between the movie and the user rating time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train_df: 58284\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from feature_analysis.data import ML100K\n",
    "\n",
    "categorical = ['user_id', 'item_id', 'gender', 'occupation', 'age_interval']\n",
    "numerical = ['timestamp', 'year', 'age', 'freshness']\n",
    "\n",
    "data = ML100K(data_dir='/DATA/', \n",
    "              categorical=categorical, \n",
    "              numerical=numerical, \n",
    "              apply_fillnan=True, \n",
    "              apply_preprocessing=False, \n",
    "              random_seed=42)\n",
    "phase_data = data.phase_data\n",
    "train_df, train_label = phase_data['train']\n",
    "train_df['label'] = train_label\n",
    "\n",
    "print(f'number of train_df: {len(train_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Analysis: Feature Correlation on numerical features\n",
    "Numerical features could be analyzed directly with the feature correlation. The output of the `df_correlation` would be the feature set with its correlation and ranked by absolute value of correlation. \n",
    "\n",
    "The result shows most of features have no highly correlated with `label`. Furthermore, `freshness` and `year` have high correlation because `freshness` is generated by `year` and `timestamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation [(-0.9994025745385305, 'year', 'freshness'), (-0.17023564184993722, 'label', 'year'), (0.16856944163951673, 'label', 'freshness'), (0.15277789320652435, 'timestamp', 'age'), (0.14378317122976503, 'age', 'freshness'), (-0.14035769097585107, 'year', 'age')]\n",
      "spearman correlation [(-0.9834729387676251, 'year', 'freshness'), (-0.1936631616037067, 'label', 'year'), (0.18701100858712852, 'label', 'freshness'), (0.12179751746853304, 'age', 'freshness'), (0.11959637376161228, 'timestamp', 'age'), (-0.11135941759729562, 'year', 'age')]\n"
     ]
    }
   ],
   "source": [
    "from feature_analysis.analysis import df_correlation\n",
    "\n",
    "copy_df = train_df.copy()\n",
    "copy_df['label'] = train_label\n",
    "\n",
    "corr_pair = df_correlation(df=copy_df,\n",
    "                           method='pearson',\n",
    "                           show_image=False,\n",
    "                           threshold=0.1,\n",
    "                           descending=True,\n",
    "                           features=['label', *numerical])\n",
    "print('pearson correlation', corr_pair)\n",
    "corr_pair = df_correlation(df=copy_df,\n",
    "                           method='spearman',\n",
    "                           show_image=False,\n",
    "                           threshold=0.1,\n",
    "                           descending=True,\n",
    "                           features=['label', *numerical])\n",
    "print('spearman correlation', corr_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Analysis: Chi-Square test of independence on categorical features and label\n",
    "\n",
    "In this section, `gender`, `age_interval`, `occupation` are considered. In order to make sure each sample in hypothesis testing is independent. In each time of hypothesis testing, only 1 movie and its label will be sampled from each user. Whole hypothesis testing would be ran 100 times and be processed by multiple testing correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_times': 100, 'significant_count': 0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_analysis.analysis import hypothesis_test\n",
    "\n",
    "copy_df = train_df.copy()\n",
    "user_df = copy_df.groupby('user_id').agg({\n",
    "    'gender': lambda a: list(a)[0],\n",
    "    'label': list\n",
    "}).reset_index()\n",
    "\n",
    "hypothesis_test(user_df,\n",
    "                feature='gender',\n",
    "                label='label',\n",
    "                times=100,\n",
    "                test_type='chi_square_independence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_times': 100, 'significant_count': 0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = train_df.copy()\n",
    "user_df = copy_df.groupby('user_id').agg({\n",
    "    'age_interval': lambda a: list(a)[0],\n",
    "    'label': list\n",
    "}).reset_index()\n",
    "\n",
    "hypothesis_test(user_df,\n",
    "                feature='age_interval',\n",
    "                label='label',\n",
    "                times=100,\n",
    "                test_type='chi_square_independence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_times': 100, 'significant_count': 0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = copy_df.groupby('user_id').agg({\n",
    "    'occupation': lambda a: list(a)[0],\n",
    "    'label': list\n",
    "}).reset_index()\n",
    "hypothesis_test(user_df.copy(),\n",
    "                feature='occupation',\n",
    "                label='label',\n",
    "                times=100,\n",
    "                test_type='chi_square_independence')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Analysis: Two Sample z-test on numerical features\n",
    "In this section, `freshness`, `age`, `year` are considered. As the same as the previous section, Only 1 movie and its label will be sampled from each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_times': 100, 'significant_count': 100}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = train_df.copy()\n",
    "user_df = copy_df.groupby('user_id').agg({'freshness': list, 'label': list})\n",
    "hypothesis_test(user_df.copy(),\n",
    "                feature='freshness',\n",
    "                label='label',\n",
    "                times=100,\n",
    "                test_type='ztest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_times': 100, 'significant_count': 22}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = copy_df.groupby('user_id').agg({'age': list, 'label': list})\n",
    "hypothesis_test(user_df.copy(),\n",
    "                feature='age',\n",
    "                label='label',\n",
    "                times=100,\n",
    "                test_type='ztest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_times': 100, 'significant_count': 100}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = copy_df.groupby('user_id').agg({'year': list, 'label': list})\n",
    "hypothesis_test(user_df.copy(),\n",
    "                feature='year',\n",
    "                label='label',\n",
    "                times=100,\n",
    "                test_type='ztest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Analysis: Feature importance on random forest model and permutation importance\n",
    "In order to run random forest model on the dataset, feature preprocessing on filling NaN value and standardizing the numerical features are necessary. In order to avoid putting high correlated features into model at the same time, `age` is used instead of `age_interval` and `freshness` is used instead of `year`, `timestamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['user_id', 'item_id', 'gender', 'occupation']\n",
    "numerical = ['age', 'freshness']\n",
    "data = ML100K(data_dir='/DATA/',\n",
    "              categorical=categorical,\n",
    "              numerical=numerical,\n",
    "              apply_fillnan=True,\n",
    "              apply_preprocessing=True)\n",
    "phase_data = data.phase_data\n",
    "train_processed_df, train_processed_label = phase_data['train']\n",
    "val_processed_df, val_processed_label = phase_data['val']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Random Forest parameter searching\n",
    "The purpose is to find the best parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/400] was ran\n",
      "[40/400] was ran\n",
      "[60/400] was ran\n",
      "[80/400] was ran\n",
      "[100/400] was ran\n",
      "[120/400] was ran\n",
      "[140/400] was ran\n",
      "[160/400] was ran\n",
      "[180/400] was ran\n",
      "[200/400] was ran\n",
      "[220/400] was ran\n",
      "[240/400] was ran\n",
      "[260/400] was ran\n",
      "[280/400] was ran\n",
      "[300/400] was ran\n",
      "[320/400] was ran\n",
      "[340/400] was ran\n",
      "[360/400] was ran\n",
      "[380/400] was ran\n",
      "[400/400] was ran\n",
      "Testing AUC: 0.80\n",
      "Best params: {'n_estimators': 175, 'min_samples_split': 19, 'min_samples_leaf': 3, 'max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "from feature_analysis.utils import parse_hyperparams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "best_auc = 0\n",
    "best_params = None\n",
    "rf_params = {\n",
    "    'n_estimators': list(range(100, 200, 25)),\n",
    "    'min_samples_split': list(range(3, 21, 4)),\n",
    "    'min_samples_leaf': list(range(3, 21, 4)),\n",
    "    'max_depth': list(range(25, 125, 25))\n",
    "}\n",
    "hyperparams_set = parse_hyperparams(rf_params)\n",
    "for idx, params in enumerate(hyperparams_set):\n",
    "    if (idx + 1) % 20 == 0: print(f'[{idx+1}/{len(hyperparams_set)}] was ran')\n",
    "    forest = RandomForestClassifier(**params, random_state=42, n_jobs=4)\n",
    "    forest.fit(train_processed_df, train_processed_label)\n",
    "    pred = forest.predict_proba(val_processed_df)\n",
    "    auc = metrics.roc_auc_score(val_processed_label, pred[:, 1])\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_params = params\n",
    "print(f'Testing AUC: {best_auc:.2f}')\n",
    "print(f'Best params: {best_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest Feature Importance\n",
    "The best parameter on the random forest is applied and set `apply_permutation_importance = False` to observe the importance from the random forest model. The drawback of feature importance from random forest is that it will be affected by high cardinality features. Therefore, permutation importance is applied in next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_name': 'auc',\n",
       " 'metric_value': 0.8025399341810802,\n",
       " 'feature_importance': [('item_id', 0.34770623517269517),\n",
       "  ('user_id', 0.22153512464789368),\n",
       "  ('age', 0.15108650083728364),\n",
       "  ('freshness', 0.14604414895992396),\n",
       "  ('occupation', 0.10938771431207134),\n",
       "  ('gender', 0.024240276070132138)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_analysis.analysis import random_forest_importance\n",
    "\n",
    "random_forest_importance(train_processed_df,\n",
    "                         train_processed_label,\n",
    "                         val_processed_df,\n",
    "                         val_processed_label,\n",
    "                         model_kwargs={\n",
    "                             **best_params, 'random_state': 42\n",
    "                         },\n",
    "                         apply_permutation_importance=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Permutation Importance\n",
    "Permutation importance is applied and different aspects on feature importance could be observed. The concern of the permuatation importance is that if there are highly correlated features, the importance of the feature would be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric_name': 'auc',\n",
       " 'metric_value': 0.8025399341810802,\n",
       " 'feature_importance': [('freshness', 0.09765077372152975),\n",
       "  ('item_id', 0.09523056666015066),\n",
       "  ('age', 0.050029208540506985),\n",
       "  ('user_id', 0.04839482177107688),\n",
       "  ('occupation', 0.04166194839046174),\n",
       "  ('gender', 0.01034771698112431)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_importance(train_processed_df,\n",
    "                         train_processed_label,\n",
    "                         val_processed_df,\n",
    "                         val_processed_label,\n",
    "                         model_kwargs={\n",
    "                             **best_params, 'random_state': 42\n",
    "                         },\n",
    "                         apply_permutation_importance=True,\n",
    "                         permutation_importance_kwargs={\n",
    "                             'n_jobs': 2,\n",
    "                             'random_state': 42\n",
    "                         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Decision\n",
    "First, the baseline feature is set as: `(user_id, item_id)` and from the previous analysis some insights could be arranged as:\n",
    "\n",
    "- On feature correlation analysis on numerical features, no feature, label pair has relative high correlation\n",
    "\n",
    "- On Chi-Squared test of independence on categorical features, None of `age_interval`, `gender`, and `occupation` shows more significant times in 100 hypothesis testing times. \n",
    "- On z-test two samples mean on numerical features, `freshness` and `year` shows possiblity of being influential feature\n",
    "- On feature importance analysis, `age` and `freshness` shows more important than others and further on permutation importance aspect, `freshness` shows most important on all of features.\n",
    "\n",
    "\n",
    "The final priority of features could be ordered as: `freshness`, `age`, `occupation`, `gender`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
